Computer Language
=================

## **Fundamental Principles**
This documentation describes the fundamental principles, upon which the new computer language is based. It covers the *reasons*, the *aims*  and the *way*  to realize the new computer language. Perhaps the most important goal of the new computer language, is to melt together all computer technology disciplines, providing one clear language, that can express anything, and that everybody can understand. The *Fundamental Principles* folder makes a lot of promises about the new language, but the *Coding Concepts* folder shows you how those promises are upheld.

This contents page will give a definition of each of the fundamental principles of the new computer language. More principles will be added in the future.

Most of these articles are not finished yet. The *Fundamental Principles*  folder contains the following articles:

### *Exchangeability*

The *Exchangeability Principles* describes things in the area of computer technology, that are traditionally separate, but will be combined to form one thing. The *Exchangeability* folder contains the following articles:

#### *Introduction*

In the future this folder should contain an introduction to the exchangeability principles.

#### *Diagram & Text Code Expression*

The idea is, that systematics can be fully expressed in text as well as in diagrams. The diagram code does not have anything missing it is: any aspect from the biggest outline to the finest detail can be clearly expressed with the diagram notation. The way storage of systematics as binary interlinked objects is separated from text code and diagram expression. 

(This article is not finished yet.)

#### *Object Oriented = Relational*

This article has not been written yet, but it should contain a description about how relational database is reconsiled with object oriented programming. The two could always be combinedly used, but it has always been a problem to make the two really one system. They were always just two separate systems, that are conjoined. The new language will turn the two principles into a single paradigm. The object oriented approach and the relational database approach, which are traditionally separate things, are turned into one language. This is intrinsic to the new design of the language. It has not been fully established yet in the programmed versions of the new computer language.

#### *Data = Code*

This fundamental principle is about the fact that a program will *not* consist of procedures operating on a database. Your program primarily is* the database. Code is just inserted into the data structure, to become part of it.

#### *Programming Language = Database*

This fundamental principle is about the fact that the code of a program is stored as a database. *Code is just data*, that describes a procedure.

This concept is fully applied inside the new design of the the computer language. It is not applied yet inside the running versions 0.9 and 2.0 of the new computer language.

#### *Design Time = Run Time*

In most programming languages there is a distinction between design time and run time. This means, that the software is programmed first, and then run. You only run it after you programmed it. If the program it is not error free, the program may crash. The principle *Design Time = Run Time*  takes away this distinction between design time and run time. This article demonstrates how you can create a program and use it at the same time. It goes too much into what happens when an error occurs. That should be covered later in *Errors & Warnings* and in *Concurrency*.

The concept has not been fully realized yet in software, but version 2.0 of the new computer language comes close to it.

#### *User = Programmer*

There is no distinction between design time and run time anymore. This makes programming software and using software blend together. Perhaps not everything will be easy to understand to every user, but the lines between creating a program and using a program will fade. The language, with which a user operates the computer, will be the same language, with which you* program software. This article further goes into this concept.

#### *Clear Cut Coding Principles*

The idea behind clear cut coding principles, is that the computer language is so accessible, that even children could pick it up, because the principles are so easy to understand, and there are not that many pittfalls. The basic parts of the coding principles could be picked up by anyone, but more advanced subjects need to be left out, because they can not be understood that easily. It is the intention for a running version of the new computer language to have sort of like a scale, a slider, that can be adjusted, limiting the amount of concepts expressed in the diagram or textual language, so that complex systems can be expressed using easier concepts, so that the general workings of a system are accessible to anyone.

#### *Attributes Are Objects*

In traditional object oriented programming languages and relational databases simple data types, also called *attributes*, are not considered objects. They have such different behavior, that we tend to approach them much different from objects. In the new computer language, however, simple objects such as numbers and dates are always objects. There are a couple of special characteristics to *simple* objects, that will be explained in the *Objects* documentation. Unifying attributes with objects makes the new computer language’s grammar less complex.

(The article is not finished yet. It is just ideas gathered up out of old documentation, yet to be turned into a new article.)

#### *Command = Executable Object*

Even more programming constructs are turned into just objects. Methods, functions, procedures, routines, commands, executables, all called *commands* in the new language, are actually objects too. Every command is a special object, that just happens to be executable. A whole chapter has been devoted to it: the *Commands* chapter. The differences between commands and normal objects are explained in it, but the essence of it is: commands are *objects*, *executable* *objects*. Turning commands and objects into the same construct makes the new computer language’s grammar less complex.

(This article is not started at yet.)

#### *Hand Signs*

The diagram notation is so clear and expressive in its forms and shapes, that you can even draw out the shapes *in the air* to clarify systematics. The new computer language also is a hand sign language for technology.

(This article is not finished yet.)

#### *Hand Writing*

Also: the diagrams can be drawn with a pencil on paper, so when you have a sheet of paper, you can also clarify the systematics of something using the diagram notation or draw out a quick sketch of systematics. However, a computer can more easily organize the diagram: you can quickly get a mess on a piece of paper, where a computer can automatically organize the diagram shapes.

(This article is not finished yet.)

#### *Hardware & Software*

The new computer language will reveal the connection between object logic and the physical hardware. It will reveal the internal workings of a computer. It will connect logic to electronics.

(This folder contains no article yet.)

#### *System Engineering = Software Engineering*

That way, the new computer language allows hardware and software developers and system engineers to work using the same language.

(This folder contains no article yet.)

#### *Internet as a Single Computer*

This document describes how the internet is turned into a single computer. There simply is no difference between a program running on your own machine and programs running on another machine on the internet. The internet is just used as one giant computer, that everybody uses and contributes to.

This document has been moved to the *Infrastructure* documentation, because it will not be part of the first versions to come of the new computer language.

The documentation is quite lengthy and will later be split up into multiple pieces. No software has been developed for it yet.

#### *Hyperlinks = Referential Structure*

This fundamental principle shows how to view hyperlinks in the new computer language. Hyperlinks are still part of a textual document, but they can also be seen as analogus to *object structures*, because they are about documents with references to other documents inside it, which is like objects with references to other objects inside it. So this fundamental principle explains how hyperlinks are exchangeable with referential structures, that can be visualized with the new computer language.

#### *Flat & Structured Interchange*

The *Flat & Structured Interchange* principles are a set of principles, that turn something flat and unstructured into something branched out and structured. It also can approach anything structured as something entirely flat. Flat and structured are completely exchangeable. Some aspects of the system are not structured by a human being anymore. The system gets structured automatically. For instance: you can not control the containment structure of objects manually anymore. The containment structure is automatically derived from the referential structure of objects.

(This article is not finished yet.)

#### *User Interface Not Procedure Oriented*

Programming interfaces have gone from procedural to object oriented. Procedures are part of an object, rather than separate procedures being executed on data. User interfaces, however, are still too much *procedure* oriented, because there are commands in a menu, instead of being able to right-click on an object and see any action you can undertake on it. Any command you can execute on an object should be listed under the context menu of that object. I first and foremost want to see a command hanging under an item, not look through a big list of commands to find the one, I can execute on my item. However, in the new system, all commands you can execute on an object, are accessible under the object itself. But also: all commands of all classes of objects are accessible as a flat list of commands. So the new system actually supports both views. Both views are exchangeable.

#### *Symbol = Creator*

This principle partly confirms the *Object Oriented = Relational* principle. *Symbol*  refers to an object oriented programming language I began to construct around the year 2001. It is a programming language, that can fully express a program in a diagram. *Creator*  refers to a programming language I began working on around 2006. The basic principle of it is, that you start off defining classes and relations, and an application is generated out of it. The principle of *Symbol = Creator* is about turning these two languages into a single programming language. This is hard, because *Creator* is based on defining *relations*, and *Symbol* was an object oriented language about a diagram notation, which on top of it all had no way to express a *relation*. This article explains how the two will be combined in the new design, to form a single language.

### *Extensibility*

Another category of fundamental principles is the *extensibility principles*. Those cover the techniques that make sure existing software is easily extensible and making sure, that *Software System* integrates with the rest of the world of computer technology. *Software System* resources should be accessible to other systems and existing resources on the internet should be accessible in *Software System*. The *Extensibility* folder contains the following articles:

#### *Introduction*

This folder is empty for now. In the future it should contain a description of what extensibility principles are.

#### *Reflection*

Reflective data is data that describes the structure of a program. The reflective data of a program for instance contains descriptions of classes. In ordinary programming languages, it is considered something special to be able to access data that describes a program, listing out all the classes and all of its members. In the new computer language the program actually *is* a description of the structure of the program. As you make the program, you are creating this data, and it is actually the program itself, that will just be run inside an engine. Any object simply has a reference to its class. You can access the full description of this class at all times.

Having this reflective data at hand at all times, makes it easy to write software that adapts its behavior to this reflective data, rather than being written for a specific data structure. That creates better extensibility.

#### *Module Integration*

In a newer version of computer language there is simply no distinction between modules anymore. It is like there is only one module running on the computer. Separate modules are simply sub-objects of one single module. An object can have a class out of any of the modules, that run on the computer or even a class out of any module on the internet.

Modules are not separate programs. They are just objects living inside the computer or on the internet. When a module contains an object with a class from another module, the object simply refers to the class as if there was not even any distinction between modules: everything is running on the same computer or on the same internet, everything is an object, and the modules are simply a benign grouping of things, that does not really create any barrier between programs.

#### *Concepts As External Modules*

Concepts are power-enhancements of software, that can be immediately applied to any system without any further programming. A concept is a special programming construct.

A *concept* is close to what some programming environments call *aspects*. But concepts are supposed to be a richer, more usable variation on aspects.

Concepts allow you to program modules, that adapt themselves to the structure of other modules, automatically extending an existing structure with an extra aspect, such as instantly enabling copy-paste actions inside a system, that originally did not support it, or instantly being able to save object structures to XML, for a system that originally did not have this functionality.

Concepts will often make use of a system’s *reflective data*.

Turning concepts into external modules instead of polluting all the code of a program with it, makes systems more easily extensible.

This article is still just a throw-together of ideas, yet to be turned into good documentation.

#### *Relational As Carbon Base*

The *Relational As Carbon Base* principle means that when making a program, you should primarily think in terms of relations between classes. The relations and classes are used as a base. They are used by *concepts*, for instance to automatically generate a user interface for the system. Also other concepts like *Undo* and *Copy & Paste* can automatically be applied to the relational structure. The concepts are tied to the relational structure. The relational structure forms the carbon base of the program, onto which other atom groups can be attached.

### *Achievability*

This sub-folder represents one of the three categories of fundamental principles: the achievability principles. The achievability principles are a set of principles, that describe how a new computer language can be developed in a limited amount of time with a limited amount of people: what techniques are employed to make that possible. It should also cover how the development of modules of *Software System* other than the programming language are made more achievable like that. The *Achievability* folder contains the following articles:

#### *Introduction*

For now contains only loose ideas about the subject of *Achievability*, yet to be turned into good documentation.

#### *Generic, No Generators*

Describes how the concept of code generators is abandoned and replaced by a better way to do it. The development of code generators is far more difficult, than an alternative method. The idea has been applied in realized software: version 2.0 of the new computer language compared to version 0.9 of the new computer language makes the transition from code generators to generic modules, that adapt themselves to a structure definition, that you assign to it. It makes it much easier to develop the new computer programming language, than when using the code generator approach.

#### *Small Code Base*

This principle is about making the code base of the new computer language as small as possible and have the rest of the computer language programmed within the new computer language itself. This fundamental principle was also proven in version 2.0 of the new computer language: the code base was reprogrammed within itself.

#### *Computer Language Programmed Within Itself*

The new computer language makes it easy to program large systems of software. But making the new computer language itself is hard. So the only way to easily make the new computer language, is to program the new computer language within the new computer language itself. This article tries to explain how this is possible. The description is lenghty and hard to understand. It covers too many technical details, instead of giving an easy presentation of the concept.

The concept *Computer Language Programmed Within Itself* has been proven* with version 2.0 of the new computer language. In that version the base of the new language is actually reprogrammed using the new language itself. All other software can be based on that, which from then on is programmed only using the new computer language.

#### *Everything Only (Lack Of Choice = Guarantees)*

In version 0.9 of the new computer language almost any part of the code, that was generated, was optional. This basically created a lot of different possible situations in which everything needed to still function correctly. The principle of *Everything Only* is the opposite: instead of making everything optional, everything is included without a choice. This limits all the possible situations, which makes things easier to test, there are no surprises and it is easy to give guarantees about a system’s functioning. This principle is not applied to every situation, but it can be applied selectively to make things easier to achieve: just do not make too many things optional. That will minimize the amount of possible situations.

This article covers the why and where it went wrong before. It is explained why this principle was come up with, but this makes it harder to read, because it is not enough a raw description of the concept. It may give you an impression of: “Why do I need to know all this? Why are you bothering me with all of this background information?”.

#### *C++ / C#*

This principle constitutes the mere fact, that the code base of the new computer language will initially be programmed using C++ or C#. It is called an achievability principle, because originally the new computer language was written in VB6 and this created a great performance barrier. Version 2.0 of the new computer language is based on C++. Version 3 of the new computer language will be based on C# and .NET.


*Author & Copyright: Jan-Joost van Zon        Date: May 18, 2009 – May 20, 2009        Location: Oosterhout, The Netherlands        Status: Finished*




## **Ideas**


*The texts below are loose ideas yet to be turned into good documentation.*



Fundamental Principles,

2008-10-16



I am analysing crap code at work now,

and I remember why I ever came up with the diagram notation.

I have to do vast analysing to see what calls upon what,

and what input is transformed and passed on to which parts

of the system.

In the diagrams you get that information basically for free.

So that must be the background of this language:

the code is the analysis, and more specifically put:

you can immediately see which parts are linked to eachother

and make use of eachother, and what input and output

goes where.



JJ


Fundamental Principles,

2008-10-17

I guess I want the new computer language to be as fundamental

as the Von Neumann architecture.

It’s totally different than what was before, but so logical we will not

change it any time soon.

JJ

Fundamental Principles,

2008-11-05



It may be a fundamental principle, that all references are registered.

It may also be fundamental principle, that possible bad behavior should not compromise your abilities for good behavior.

So the use of your creativity should not be put to a limit by possible bad behavior of others.

If you can make a system that completely work following these principles, than that would be great.



The Fundamental Principles can be guarantees the system must give and should not be broken.



JJ


Fundamental Principles,

2008-11-05



The bad behavior principle is why registration of all references

SHOULD be designed for good practice to work, without having to consider the bad behavior.

Deterring bad behavior should be completely separately adressed,

because also in the design of the new computer language,

bad behavior should not have to be considered, because it it may not compomise my creativity

by having to think about all sorts of possible bad behavior as I try to design a language to do good with.

Programming USING the language should be the same: you should only have to separately address

possible bad behavior, not while you are designing a system that works for good behavior.



JJ




CL,

2008-11-13



Als allerlei dingen aan elkaar gebonden zijn in een systeem,

waarom zitten we dan allemaal coderegels te bestuderen en niet

gewoon aan elkaar gekoppelde objecten?



JJ



CL,

2008-11-30

It happens a lot, that a design pattern already existed

for a long time, but only gets popular, when you make

it an actual language element.

So all good patterns must be present in the programming

language itself, or the whole world of software development

will not use it at all and will lag behind on progress that

already took place.

JJ


Computer Language,

2008-12-22



That Concept construct I want in my programming language seems to have existed forever:

http://www.lucas.lth.se/lucas-dagar/2002/slides2002/hedin.pdf



It seems, that the problem with good concepts, such as Aspect Oriented Programming and design patterns, is that they are not used, because they do not become part of the programming language. Those ideas could be made part of the programming language, but instead they are introduced as methodology.

If they are made part of the language, then hobbyists will be more likely to use it.



Many beautiful concepts come up with in the 70's, 80's and 90's are not used, because not enough people know about it.

Many of those concepts could be made part of a programming language itself, so that more people, trying out programming, are tempted to experiment with them. If they don't have it available in the language, many concepts will be forgotten about, and the whole proffession of software programming lags behind on itself.



That is why I need to get myself educated about all the ideas, that already existed, so that I know how to give them a place in my own programming language.

I need to converge existing ideas, and turn them into new products. That should be my job, rather than just reinventing everything. That would make me more effective in my job. I should be less individualistic. I can do much better work when I use ideas, that already existed before I was born. Those people were not stupid.



JJ

Computer Language,

2008-12-22



I ask myself if anything original is left to my language,

when I orient myself into existing ideas.



It is sort of soothing, though, that I am not doing everything by myself,

but are just recombining existing ideas.



JJ


Computer Language,

2008-12-22



Als hedendaagse programmeertechnieken zo geweldig zijn,

waarom is alles dan nog steeds zo'n haperende troep.

Met name als je aan het programmeren bent.



JJ


Computer Language,

2008-12-23



Heel veel van die dingen kom je gewoon niet vanzelf tegen.

En dat is jammer. Want zo leren de meesten programmeren:

door dingen vanzelf tegen te komen.

En dat stimuleer je door het in de taal zelf op te nemen.



JJ


Software Development,

2009-01-16



Dat electronic sheep geeft me echt het gevoel,

dat als software niet afgrijselijk mooi is,

het eigenlijk geen indruk maakt.



JJ



New Computer Language,

2009-02-12

You can put a breakpoint on members of specific objects, not just a member of a class.

Just as well you can put a breakpoint on any data member’s get or set procedures or other system procedures.

JJ

New Computer Language,

2009-02-12

‘Not too much derivation’ could be a Fundamental Principle, for the same reasons as Lack of Choice = Guarantees.

JJ

Commands / Computer Language,

2009-03-13

What if you can say: I want a command on that object, that calls that program's this and that command.

The reason programming is hard, is because programming languages are too hard.

The user knows what he wants. Why is it any more difficult to realize something on the computer,

than to just tell the computer what it is you want?

JJ


Computer Language,

2009-03-13

Folders, containing files and other folders?

Presented in a tree structure without it even actually looking like a tree?

Why is it you are presenting only the IDEA of containment,

and not how containment actually looks?

JJ

Computer Language,

2009-03-13

Icon display and double clicking on them, showing THEIR contents,

is ALMOST what I want to see regarding containment,

except, that you will actually see the zooming in animate.

JJ

Computer Language,

2009



Zodat software ontwikkelaars nog minder weten van wat er op fysiek niveau gebeurt...

Op zich wel mooi om je op conceptueel niveau bezit te houden,

maar het creeert ook meer afstand ten opzichte van wat er fysiek gebeurt.

Dat heb je al met SQL. Dat wordt niet per so nog erger met LINQ, maar

dat houdt het wel in stand. Er zijn al tal van programmeurs, die verrotte queries schrijven

en daarna de database de schuld geven, omdat ze geen flauw benul hebben

van wat er onder water eigenlijk gebeurt. Het beste snap je zowel dingen op conceptueel niveau,

als de fysieke uitvoering ervan.

Ik zie daar wel een voordeel van mijn eigen taal in. Die verbindt die twee en maakt ze even toegankelijk.



JJ


Computer Language,

2009-03-31



Who is this guy:

http://strlen.com/index.html



Perhaps that guy built a model

around the OpenGL library.

He's probably just a darn-good programmer too.

JJ

\-----

Computer Language,

Fundamental Principles,

2009-03-31

It is possible to program as simply in assembly

as you do in the new computer language, but

in the new computer language you are more dictated

to work within a certain paradigm.

You can apply the paradigm in assembly language too,

but in assembly you can more easily break those rules.

In the new computer language the rules are more imposed.

Actually, in the new computer language you are also not obliged

to do it that way.

In an object oriented language you can 

still program procedural, but it is just, that objects and classes

are a programming construct of an importance equal to

that of procedures.

In the new computer language it is the same way:

relations and concepts are programming constructs of equal importance, but you do not have to use them.

Nevertheless, they are so present as a programming construct,

that you start to use them anyway.

Actually a lot of programmers took a long time to realize

what they need classes for to program with.

But they have been applying them for years, because they

have been USING classes. They just hadn't been programming classes.

In the new computer language it is the same way:

concepts, relations and objects and commands and everything

are clearly present in the framework libraries.

You will be using them before you start to program them yourself.

In assembly, you could program in an object oriented way

with classes. It is a matter of working in a certain fashion

and yes, the syntax looks much different, but you are still

modeling with classes and objects.

JJ




Computer Language,

2009-04-08



Just about everything in text code is reference by name.

You do not physically see connections between things.

The correspondence of names creates the connection.

That is what is hard about analysing existing code.



JJ

New Computer Language Functional Design,

2009-04-16



A user-defined order number of a user-defined sorting,

and the use of aliases prevents dead links .

(you could also do a kind of automatic aliasing: when a link is not found, the history of that link would be stored inside the container of the leaf, and 


this could be used to offer a suggested new linkage, when the dead link was attempted to be accessed.



JJ




NCL Fundamental Principles,

2009-04-20



Connections between system elements in text code are ALWAYS established purely through name correspondence.

That's one of the problems with analysing text code. You have to aquaint yourself with the names,

before you can start to understand the connections between things.

And through those connections, understanding which are main things, which are less important things,

which are big things, which things are unused and what are the first things or prime things,

that a program does.

An understanding of those things is what the result of such analysis is.

Text code alone never reveals such information immediately,

so understanding text code is always accompanied by either explanation through documentation

or by analysing the code.



In diagrams, the connections and the prominence of things are already visible to the naked eye,

so the connections and hierarchy between things are apparent at a much earlier stage (more or less immediately),

when looking at other people's code.



One thing, not apparent from text code OR diagrams is: WHY. Diagrams display the workings of a system,

but not what we need those workings for. For that you still need documentation.



Constructing text code to be totally self-documenting in my view is a total lie.



JJ


NCL Fundamental Principles,

2009-04-20



Code along with comment can not easily point out things like the following.

Simply: where does the program start?

What are the prime things the program does and where does it do it?

What prime components is the program composed of and how do they relate to eachother?



WHY is the program structured like this?

What is the program FOR?



The only way to add this to the code, in my view is to add a txt file, named ReadMe.txt

or something and tell those things there.



JJ


CL Fundamental Principles,

2009-05-14



The problem with learning to understand how computer works,

by just playing with it, is that what really happens inside the computer

is invisible.



JJ


Computer Language,

2009-06-12

All we are working with is just feedback from what is really going on inside the computer.

We are just tapped in and only tap off some of what's going on inside that thing.

JJ

Computer Language,

2009-05-02

I might not have a good spot or good explanation about how assembly seamlessly integrates into the language. This is part of the achievability principles, but also makes use of the Binaral concept and the Value concept too.

JJ

Fundamental Principles,

2009-06-14

Hoeveel van die beloftes worden al waargemaakt in de coding concepts & data concepts?

\> Anders denken ze: "Jij praat poep".

Zou je na het uitwerken van Input / Output NOG een belofte kunnen doen, aangaande concurrency resolution?

JJ

Internet,

2009-08-14



http://74.125.77.132/search?q=cache:T0M\_SRpZE9gJ:www.bofh.org.uk/2008/04/07/code-is-data-and-it-always-has-been+code+is+data&cd=2&hl=nl&ct=clnk&gl=nl





Possible response :



I think you are putting to much effort into answering this question.

I would put it more bluntly.

'Code = data' is not an idea. It is a fact.



It is character data or binary data, with a certain format, that can be interpreted by the computer.

It is a description of linkages between program elements.

Not much different from a spread sheet, which is also contains linkages between data and stuff that can be executed.



Code is merely data, that describes a program.



You do not need reflection or code generation for that to be a fact. It is what it is: data that describes a program.



JJ



Fundamental Principles,

2009-08-18



Data wordt heen en weer geflipperd,

en procedures delegeren allemaal naar elkaar door.

En soms delegeren en er een beetje veel procedures naar elkaar door,

en flippert er een beetje veel data heen en weer. Complexiteit noemen we dat dan.

En als er te veel complexiteit is ten opzichte van de functionaliteit,

dan noemen we dat spaghetti.

JJ


Ideas,

2009-10-28



The word architecture is something I also do not want to hear.



JJ



Fundamental Principles,

2009-12-02



Of mensen flyers krijgen is afhankelijk van betalingsachterstanden.

Het grappige is, dat als je erover rapporteert en je kent de logische verbanden

van de twee eigenschappen niet, dan kom je er misschien gaandeweg per ongeluk achter,

dat de twee verband houden.

In NCL zie je het verband (makkelijker), omdat je de koppeling tussen de afweging en de velden ziet.

Je ziet dus een indirecte koppeling tussen de twee velden,

omdat je de programma logica ertussen ziet.

Is dit zo? Zie je in de diagrammen ook indirecte verbanden snel? Net zoals je directe verbanden snel ziet?



JJ



Fundamental Principles,

2009-12-02



Als dingen in het programma dicht bij elkaar staan, zie je het misschien wel, 

maar ik zou misschien in de toekomst meer mogelijkheden willen zien om indirecte verbanden zichtbaar te maken.



JJ



\> Fundamental Principles,

2010-05-07

If everything starts out freely definable, then you make a system by creating restrictions. So systematics are defined through restrictions. If there are not restrictions, you can program anything programmable. After you create a system of classes, someone else may create a system of objects, in which not everything is programmable, but only very specific things are programmable.

JJ


Fundamental Principles,

2010-04-25 ~

How does Aquima impose rules.

No, back to Circle.

Everything is possible with all the constructs available. But awareness of all the custruct should inspire you to pick the right solution in the right situation.

And now Aquima.

You always have to pick one out of 5 first.

In a way, in Circle, you always have to pick one out of 12 first, or something.

You have to pick a construct…

I am not going to brainstorm more about these fundamental things. I can not get my head around it right now.

JJ


Fundamental Principles,

2010-02-17



To defend the references lines vs. name correspondence

you can say that even small programs consist of tens of thousands

of references. Each operator, function call or variable reference

is a reference. So basically a typical code line consists of between 3 and 20 references.



JJ


Fundamental Principles,

2010-03-25



Take the following question: There is a function. What other functions use it, and which functions use those functions?

This is a question that often needs to be answered when you analyse existing computer code. And this is a difficult question to answer. In most programming environments answering this question requires extensive analysis of the code, even when you have a tool for searching references. It gets worse if there the involved functions are not only used internally by a program, but also used by yet again other programs.



The diagram notation of NCL actually makes this otherwise difficult to extract information visible instantly. This is a big benefit of the NCL.

You might have to use coloring to make the information pop out of the diagram, but using the diagram notation it is evident how to easily highlight this.



JJ



Fundamental Principles,

2010-03-25



To prove the usability of the diagram language, the best thing to do is to be able to apply the notation inside existing environments and apply it to existing code and programs. Then it becomes evident where the benefits are.



JJ


Fundamental Principles,

2010-03-19



Kwaliteit, correctheid en elegantie de eisen waaraan een computerprogramma moet voldoen?

Dat was 50 jaar geleden. Ik ben geen brave volgeling. Ik heb daar een andere visie op. Ik zeg:

Bruikbaarheid, effectiviteit en eenvoud. Dat zijn de eisen waaraan een computerprogramma moet voldoen.



JJ


Fundamental Principles,

Low and high coupling,

2010-04-16

\> Turns out that the definition of low-coupling I use here is not the one

`    `generally used.

I have found two definitions of the term low-coupling:

One definition is a system's actually being composed of less connections.

Another definition is connecting systems through interfaces, with limited and defined sets of members.

\> And I found more definitions later.

A combined (mis)conception is that both are the same thing.

The first definition is actually what it should mean in my view: a system's being composed of less connections.

In the story below I try to explain why communication through interfaces does not

necessarily mean that the system is composed of less connections.

What low-coupling tries to solve is limitation of (possible) connections to create clarity about how systems interface with eachother.

In high-coupled situations any system element could potentially be accessing any other system element,

while in low-coupled situations systems only access eachother though defined interfaces: a set of accessible system elements,

while the rest of the system is not accessible.

This is handy for being able to change the way systems connect to eachother,

when for instance a piece of the system is discontinued or replaced,

or to offer an easy way to connect new pieces of system to existing interfaces.

I think the terms loose coupling or high coupling are inaccurate terms.

I think a better way to describe it would be clear coupling or unclear coupling.

The thing with high and low coupling is not necessarily that there

are more or less connection points in either situation,

but that in case of what is called low coupling,

it is clearer to see at what points systems connect

and a limit is imposed onto at what points systems could connect.

There is something most programmers fail to see in case of high-coupling.

The argument against it is: any member could be accessing any other member.

But the thing is: any member is not accessing any other member,

it is just not easy to see which members access which other members.

There is also something most programmers fail to see in case of low-coupling.

Programmers tend to see the number of interfaces as the absolute number of connections.

However, there are many more connections as interfaces also have disparate members,

that can be separately connected to.

Each connection to a member of an interface is a separate connection.

Each method call, call upon a data member, filling in of a parameter,

assignment, indirection, etcetera, is a connection. Those connections are there in either low-coupling or high-coupling situation.

In fact, if you make an interface, but you make it too elaborate, you end up with a highly coupled situation again:

any member of the interface could be connected to and you can not easily see which members are used and which are not.

In an elaborate interface it is still not clear which which members access what other members.

While supposedly there would only be one connection. Yeah right.

In a finished system in either a high-coupling or low-coupling situation,

both situations actually show the same number of connection points between members,

variables, etcetera.

So low coupling does not really mean less connection points,

just clarity and limitation of the possible points of connection.

Low coupling: the interfacing is clear and constrained.

High coupling: the interfacing is not easy to see and 

it is not defined which members are potentially accessed in later sofware developments.

The problem with allowing more possible connections is that potentially more connections are made, but that does not mean that this is necessarily what is happening.

What's forgotten, is that if you connect to a single interface, you do not really

have one connection. There can be many connections to the numerous parts of the interface.

The term low-coupling is even in contradiction with itself.

Given a finished system, the supposedly high-coupled version would actually contain less connections,

than the low-coupled version. The low coupled version would contain more connections,

because on top of the members accessing eachother, they are separeted by interfaces,

creating more indirections between their connections, and these indirections are connections in itself.

You first need to connect to the interface, and then you connect to the member.

Theoretically in a low coupling situation there are actually more connections, because

instead of connecting to a data member directly, first there is connected to an interface,

and then to the data member, and maybe even not directly with the data member,

but with some adapters in between. So actually, in a finished system low coupling

may have more connections than the high coupling variation.

So low-coupling and high-coupling are the illusion of having less connections.

The situation solved by low-coupling is not having less connections, but having more insight and control over those connections.

Insight into the connections in an existing system, and control over the possible connections when a system is changed.

There is another thing that does not work well in low-coupling, while it should actually be the stuff that low-coupling should be solving.

If a low-coupled situation changes, you might end up with a lot of unused interface members, of which you can not easily see that they are not required anymore.

So that is the inverse of not knowing what is used: not knowing what is not used anymore.

So you have a cluttered interface with members that are not used of which you do not know that you could remove them.

When you have an interface, and only 5% of the interface is still used, you still have the same problem as in the highly coupled situation:

you have a ton of members and you do not know which are accessed by what.

Low-coupling is there in order to be able to know how systems interface and to be able to facilitate controlled changes inside those systems.

It is about readability, not about the actual absolute number of connections.

I think the coupling and cohesion are irrational words, because the number of connections is not less in a supposedly low-coupled situation, the number of connections is actually greater, only the ways systems are connecting to eachother are defined in a way clearer for a humans to read and connections are restricted for the sake of future changes. It is actually more about readability than anything else.

Whether you connect to members directly or group the connections into interfaces: all the connections are still there, actually you have increased the number of connections by first having to connect to the interface.

NCL would solve this for a great part and easily show that the low-coupled (high-interfaced) version actually has more connections than the high coupled (low-interfaced) version.

In NCL the readability of the highly coupled system will be better than in other languages, especially when the lines will be regroup as they go from sources to targets.

I just forgot how valuable that part of the notation could be when it comes to reading how systems interface with eachother.

Each grouping of lines could potentially be replaced by an interface, only then you would end up with too many interfaces again.

NCL with the use of regrouping of lines as they go from sources to targets would make it easier to automatically explicitly define the interfacing points, or make it easier to spot a place in the system in which it looks appropriate to create an interface in between.

But if you create a derived interface for each user of an interface you have actually applied to concept of low-coupling, yet you have created more complexity by creating an insane amount of interfaces.

Clearly defined interfaces are still valuable in NCL, and do not all of a sudden become unnecessary, but they DO create more connections, rather than less if you put more interfaces in between. However proper interfaces can make the system more readable.

(Low-coupling is not the same as encapsulation. But both are solved using interfaces.

Both low-coupling and encapsulation (data-protection) are concepts that are applied using the concept of interfaces, but they attempt to solve different problems,

so they are not the same thing. Low-coupling should be about complexity reduction or complexity tangibility, encapsulation should be about data protection and stability.

So one is about understandability of a system, and the other is about how easily we can thump over a system.)

So the technique of low-coupling does not create less connections. So low-coupling it is not an exact science of creating less connections, because putting an interface in between

actually creates more connections. It is about limitation of complexibility, tangibility of complexity and prevention of complexity. The low-coupling techniques can help in this, but going too far with it actually create more complexity, people just forget to count the actual connections and only count the interfacing points over which multiple connections can be made.

Furthermore, the rules of interfacing are not enforced by the machine, but by human hand.

You will not devise a system that prevents complexity, it will be humans that prevent complexity, by making things more readable for himself, making it less likely for humans to break their own rules, and humans imposing rules onto another humanbeings.

Programmers usually get emotional, irrational and upset, when you state that low-coupling is not an exact science and not necessarily required. They irrationally think it is an exact science, because they are selectively forgetting and imagining connections that are or are not there, because in their head they select a set of connections and forget about connections that are still there.

It is a clear case where programmers think they are dealing with an exact science, defend it to the death, while they are only dealing with things that are esthetic and simply make things more readable and tangible through the coding techniques available today. 

But a lot of times programmers yell at me: "That is the wrong way to go, because it creates a higher degree of coupling!", while in reality, they are just arbitrarily imagining or ignoring certain connections.

JJ


Fundamental Principles,

Low and high coupling,

2010-04-16

Actually designing a system in which one component

uses a very sober set of member of another component,

thus limiting the number of connections in the design.

It is not the interface that solves it, but the fact that you use a sober set of members.

The actual low degree of connections from one module to the other

makes it low coupling regarless of an interface being in between or not.

JJ


About coupling,

2010-04-16



http://martinfowler.com/ieeeSoftware/coupling.pdf



JJ


Coupling,

2010-04-16



There are more definitions to low coupling:

\- Using a mutual interface for multiple types of objects,

`   `so that the consumer is not bound to the classes, but to the interface.

\- To prevent having to change n things, you let them refer to a bridging 1 thing,

`   `that connects to the targeted resource.

\- You can separate things into layers so that people of different disciplines can 

`   `work on the layer they specialized in.

\- When you want to keep storage separated from presentation,

`   `possibly allowing multiple representations of the same data,

`   `and you want to be able to change the data model.

`   `(At one point the data model changes so much you can not 

`    `prevent the interface of the bridge to change or even the user interface to change,

`    `or you are going to have to keep your data model backwards compatible,

`    `something that you were trying to work around with the bridge.)

So simply trying to make things that are actually independent on eachother,

sort of independent of changes to the dependency, you build a bridge between them.

It does require additional code, additional connections and wiring, adds complexity.

I would not recommend putting a bridge between any two objects.

That would create incredible complexity. How is that going to help you change the code?

So you have to apply this when it is useful.

I can imagine that an ESB allows you to define interfaces / adapters between any two resources.

Or offer the same interface to multiple programs or the give multiple resources the same interface, or create bridges between systems.

JJ


Coupling,

2010-04-16

More brainstorming.

All this bridging has nothing to do with the cohesion they often talk about.

JJ


Fundamental Principles,

2010-04-20



To analyse if something is used anymore by executing a search,

when you an extra data access layer in between you can not easily see if something is no longer used or not.



JJ


